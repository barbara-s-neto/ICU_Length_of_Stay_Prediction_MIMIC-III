{"cells":[{"cell_type":"markdown","id":"da1d1427","metadata":{},"source":["# ICU Length of Stay Prediction - MIMIC-III Pipeline\n","\n","## üéØ Objective\n","Predict ICU stay duration using PySpark ML on MIMIC-III dataset\n","\n","## üìä Data & Constraints\n","- **Sources**: 6 MIMIC-III tables (CHARTEVENTS, LABEVENTS, ICUSTAYS, etc.)\n","- **Filters**: \n","        - Patient Age 18-80\n","        - LOS 0.1-15 days\n","        - Valid time sequences\n","- **Timeframe**: Vitals (first 24h), Labs (6h pre to 24h post ICU)\n","\n","## üîß Features (39 total)\n","- **Demographics (2)**: Age, gender\n","- **Admission (8)**: Emergency/elective, timing, insurance\n","- **ICU Units (6)**: Care unit types, transfers\n","- **Vitals (11)**: HR, BP, RR, temp, SpO2 (avg/std)\n","- **Labs (8)**: Creatinine, glucose, electrolytes, blood counts\n","- **Diagnoses (4)**: Total count, sepsis, respiratory failure\n","\n","## ü§ñ Models & Results\n","- **Linear Regression**: \n","- **Random Forest**: \n","\n","## ‚òÅÔ∏è Infrastructure\n","- **GCP Dataproc**: 6x e2-highmem-4 workers (28 vCPUs, 224GB RAM)\n","- **Optimizations**: Smart sampling, aggressive filtering, 80/20 split\n","\n","\n","\n"]},{"cell_type":"markdown","id":"f7c8375f-7f35-415f-8288-2ff2193e6af0","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"id":"89ed6638-09bf-4620-89fe-2bb2c00d86e6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ All imports loaded successfully!\n","‚è∞ Notebook started at: 2025-06-01 11:06:06\n"]}],"source":["# Core PySpark imports\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql.window import Window\n","\n","# Machine Learning imports\n","from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n","from pyspark.ml.regression import RandomForestRegressor, LinearRegression #, GBTRegressor\n","#from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n","from pyspark.ml.evaluation import RegressionEvaluator #, MulticlassClassificationEvaluator\n","#from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","#from pyspark.ml import Pipeline\n","\n","from datetime import datetime, timedelta\n","import time\n","\n","print(\"‚úÖ All imports loaded successfully!\")\n","print(f\"‚è∞ Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"]},{"cell_type":"markdown","id":"4f9d1810-67b2-471e-97d2-b8fda7db9728","metadata":{},"source":["## Setup Spark Session"]},{"cell_type":"code","execution_count":2,"id":"a15f1fca-5bf8-4e10-bdca-a6faa11ca17a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","25/06/01 11:06:09 INFO SparkEnv: Registering MapOutputTracker\n","25/06/01 11:06:10 INFO SparkEnv: Registering BlockManagerMaster\n","25/06/01 11:06:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n","25/06/01 11:06:10 INFO SparkEnv: Registering OutputCommitCoordinator\n"]},{"name":"stdout","output_type":"stream","text":["‚úÖ Spark session created successfully!\n","üìä Spark Version: 3.5.3\n","üîß Application Name: Forecast-LOS\n","üíæ Available cores: 2\n","\n","‚è∞ Spark session initialised at: 2025-06-01 11:06:16\n"]}],"source":["spark = SparkSession.builder \\\n","        .appName(\"Forecast-LOS\") \\\n","        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n","        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n","        .config(\"spark.sql.shuffle.partitions\", \"400\") \\\n","        .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n","        .config(\"spark.sql.adaptive.localShuffleReader.enabled\", \"true\") \\\n","        .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"256MB\") \\\n","        .config(\"spark.sql.adaptive.coalescePartitions.minPartitionSize\", \"128MB\") \\\n","        .config(\"spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes\", \"256MB\") \\\n","        .config(\"spark.sql.files.maxPartitionBytes\", \"128MB\") \\\n","        .config(\"spark.network.timeout\", \"800s\") \\\n","        .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n","        .config(\"spark.executor.memory\", \"24g\") \\\n","        .config(\"spark.executor.cores\", \"4\") \\\n","        .config(\"spark.executor.instances\", \"12\") \\\n","        .config(\"spark.driver.memory\", \"8g\") \\\n","        .getOrCreate()\n","\n","print(\"‚úÖ Spark session created successfully!\")\n","print(f\"üìä Spark Version: {spark.version}\")\n","print(f\"üîß Application Name: {spark.sparkContext.appName}\")\n","print(f\"üíæ Available cores: {spark.sparkContext.defaultParallelism}\")\n","print(f\"\\n‚è∞ Spark session initialised at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"]},{"cell_type":"markdown","id":"7e13163e-55dc-4046-95b0-4815723d0581","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":3,"id":"62936c54-45ab-4c03-a8ec-fc3d87f68721","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["üè• Loading MIMIC-III CSV files...\n","üìÇ Loading CHARTEVENTS table... [GZIP COMPRESSED]\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["üìÇ Loading LABEVENTS table... [GZIP COMPRESSED]\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["üìÇ Loading ICUSTAYS table...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["üìÇ Loading PATIENTS table...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["üìÇ Loading ADMISSIONS table...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["üìÇ Loading DIAGNOSES_ICD table...\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 9:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["\n","‚úÖ Tables loaded successfully!\n","\n","‚è∞ Data loaded at: 2025-06-01 11:06:48\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["DEBUG = True\n","\n","if DEBUG:\n","    MIMIC_PATH = \"gs://dataproc-staging-europe-west4-719881989993-sa4vn92s/mimic-short\"\n","else:\n","    MIMIC_PATH = \"gs://dataproc-staging-europe-west4-719881989993-sa4vn92s/mimic-data\"\n","\n","\n","\n","print(\"üè• Loading MIMIC-III CSV files...\")\n","\n","\n","print(\"üìÇ Loading CHARTEVENTS table... [GZIP COMPRESSED]\")\n","if DEBUG:\n","    chartevents_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").csv(f\"{MIMIC_PATH}/CHARTEVENTS.csv\")\n","else:\n","    chartevents_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").csv(f\"{MIMIC_PATH}/CHARTEVENTS.csv.gz\")\n","\n","\n","\n","\n","print(\"üìÇ Loading LABEVENTS table... [GZIP COMPRESSED]\")\n","if DEBUG:\n","    labevents_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").csv(f\"{MIMIC_PATH}/LABEVENTS.csv\")\n","else:\n","    labevents_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").csv(f\"{MIMIC_PATH}/LABEVENTS.csv.gz\")\n","\n","\n","#print(\"üìÇ Loading INPUTEVENTS_MV table... [GZIP COMPRESSED]\")\n","#inputevents_df = spark.read.option(\"header\", \"true\") .option(\"inferSchema\", \"false\") .csv(f\"{MIMIC_PATH}/INPUTEVENTS_MV.csv.gz\")\n","\n","\n","\n","####\n","\n","print(\"üìÇ Loading ICUSTAYS table...\")\n","icustays_df = spark.read.option(\"header\", \"true\") .option(\"inferSchema\", \"true\") .csv(f\"{MIMIC_PATH}/ICUSTAYS.csv\")\n","\n","print(\"üìÇ Loading PATIENTS table...\")\n","patients_df = spark.read.option(\"header\", \"true\") .option(\"inferSchema\", \"true\") .csv(f\"{MIMIC_PATH}/PATIENTS.csv\")\n","\n","print(\"üìÇ Loading ADMISSIONS table...\")\n","admissions_df = spark.read.option(\"header\", \"true\") .option(\"inferSchema\", \"true\") .csv(f\"{MIMIC_PATH}/ADMISSIONS.csv\")\n","\n","print(\"üìÇ Loading DIAGNOSES_ICD table...\")\n","diagnoses_df = spark.read.option(\"header\", \"true\") .option(\"inferSchema\", \"true\") .csv(f\"{MIMIC_PATH}/DIAGNOSES_ICD.csv\")\n","\n","\n","\n","# Display basic information about loaded tables\n","print(\"\\n‚úÖ Tables loaded successfully!\")\n","#print(f\"üìä ICUSTAYS: {icustays_df.count():,} rows √ó {len(icustays_df.columns)} columns\")\n","#print(f\"üìä PATIENTS: {patients_df.count():,} rows √ó {len(patients_df.columns)} columns\") \n","#print(f\"üìä ADMISSIONS: {admissions_df.count():,} rows √ó {len(admissions_df.columns)} columns\")\n","#print(f\"üìä CHARTEVENTS: {chartevents_df.count():,} rows √ó {len(chartevents_df.columns)} columns\")\n","#print(f\"üìä LABEVENTS: {labevents_df.count():,} rows √ó {len(labevents_df.columns)} columns\")\n","#print(f\"üìä INPUTEVENTS_MV: {inputevents_df.count():,} rows √ó {len(inputevents_df.columns)} columns\")\n","\n","\n","\n","print(f\"\\n‚è∞ Data loaded at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"]},{"cell_type":"markdown","id":"9e8e7157-1230-41d3-8f41-1117b62fdb55","metadata":{},"source":["## Features Engineering\n","\n","Current features for regression:\n","\n","- Demographics (age, gender)\n","- Admission characteristics (emergency vs elective, timing)\n","- ICU unit types and transfers\n","- Time-based features (weekend, night admissions)\n","- Medical data\n"]},{"cell_type":"markdown","id":"8763e6d7-4ba5-439b-8e2b-ba16cf607a3e","metadata":{},"source":["## Extracting Data From ICUSTAYS"]},{"cell_type":"code","execution_count":4,"id":"9f1d7adb-eac0-4071-b252-a04268f0c767","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 1: Creating base ICU dataset with patient demographics...\n"]}],"source":["print(\"üìä Step 1: Creating base ICU dataset with patient demographics...\")\n","\n","base_icu_df = icustays_df.alias(\"icu\") \\\n","    .join(patients_df.alias(\"pat\"), \"SUBJECT_ID\", \"inner\") \\\n","    .join(admissions_df.alias(\"adm\"), [\"SUBJECT_ID\", \"HADM_ID\"], \"inner\") \\\n","    .select(\n","        # ICU stay identifiers\n","        col(\"icu.ICUSTAY_ID\"),\n","        col(\"icu.SUBJECT_ID\"), \n","        col(\"icu.HADM_ID\"),\n","        \n","        # Target variable - Length of Stay in ICU (days)\n","        col(\"icu.LOS\").alias(\"ICU_LOS_DAYS\"),\n","        \n","        # ICU characteristics\n","        col(\"icu.FIRST_CAREUNIT\"),\n","        col(\"icu.LAST_CAREUNIT\"), \n","        col(\"icu.INTIME\").alias(\"ICU_INTIME\"),\n","        col(\"icu.OUTTIME\").alias(\"ICU_OUTTIME\"),\n","        \n","        # Patient demographics\n","        col(\"pat.GENDER\"),\n","        col(\"pat.DOB\"),\n","        col(\"pat.EXPIRE_FLAG\").alias(\"PATIENT_DIED\"),\n","        \n","        # Admission details\n","        col(\"adm.ADMITTIME\"),\n","        col(\"adm.DISCHTIME\"), \n","        col(\"adm.ADMISSION_TYPE\"),\n","        col(\"adm.ADMISSION_LOCATION\"),\n","        col(\"adm.INSURANCE\"),\n","        col(\"adm.ETHNICITY\"),\n","        col(\"adm.HOSPITAL_EXPIRE_FLAG\").alias(\"HOSPITAL_DEATH\"),\n","        col(\"adm.DIAGNOSIS\").alias(\"ADMISSION_DIAGNOSIS\")\n","    )\n","\n","# Calculate age at ICU admission\n","base_icu_df = base_icu_df.withColumn(\"AGE_AT_ICU_ADMISSION\", \\\n","                                     floor(datediff(col(\"ICU_INTIME\"), col(\"DOB\")) / 365.25)) \\\n","                                     .filter(col(\"AGE_AT_ICU_ADMISSION\").between(18,80))"]},{"cell_type":"markdown","id":"595638e6-74f7-4f2f-a7e5-1fc692089206","metadata":{},"source":["## Extracting Categorical Features"]},{"cell_type":"code","execution_count":5,"id":"d28d34e6-83c3-40ae-95d0-71f9929397a1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 2: Engineering categorical features...\n"]}],"source":["print(\"üìä Step 2: Engineering categorical features...\")\n","\n","base_icu_df = base_icu_df \\\n","    .withColumn(\"GENDER_BINARY\", when(col(\"GENDER\") == \"M\", 1).otherwise(0)) \\\n","    .withColumn(\"IS_EMERGENCY_ADMISSION\", \n","                when(col(\"ADMISSION_TYPE\") == \"EMERGENCY\", 1).otherwise(0)) \\\n","    .withColumn(\"IS_ELECTIVE_ADMISSION\", \n","                when(col(\"ADMISSION_TYPE\") == \"ELECTIVE\", 1).otherwise(0)) \\\n","    .withColumn(\"CAME_FROM_ER\", \n","                when(col(\"ADMISSION_LOCATION\").contains(\"EMERGENCY\"), 1).otherwise(0)) \\\n","    .withColumn(\"HAS_MEDICARE\", \n","                when(col(\"INSURANCE\") == \"Medicare\", 1).otherwise(0)) \\\n","    .withColumn(\"IS_WHITE_ETHNICITY\", \n","                when(col(\"ETHNICITY\").contains(\"WHITE\"), 1).otherwise(0))"]},{"cell_type":"markdown","id":"9ca22bc8-8dd5-4d30-9cb9-0f366da21d76","metadata":{},"source":["## Extracting ICU Unit Types"]},{"cell_type":"code","execution_count":6,"id":"6617c3f2-75b9-4fa0-93a8-7161d0c2dd57","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 3: Creating ICU unit type features...\n"]}],"source":["print(\"üìä Step 3: Creating ICU unit type features...\")\n","\n","base_icu_df = base_icu_df \\\n","    .withColumn(\"FIRST_UNIT_MICU\", \n","                when(col(\"FIRST_CAREUNIT\") == \"MICU\", 1).otherwise(0)) \\\n","    .withColumn(\"FIRST_UNIT_SICU\", \n","                when(col(\"FIRST_CAREUNIT\") == \"SICU\", 1).otherwise(0)) \\\n","    .withColumn(\"FIRST_UNIT_CSRU\", \n","                when(col(\"FIRST_CAREUNIT\") == \"CSRU\", 1).otherwise(0)) \\\n","    .withColumn(\"FIRST_UNIT_CCU\", \n","                when(col(\"FIRST_CAREUNIT\") == \"CCU\", 1).otherwise(0)) \\\n","    .withColumn(\"FIRST_UNIT_TSICU\", \n","                when(col(\"FIRST_CAREUNIT\") == \"TSICU\", 1).otherwise(0)) \\\n","    .withColumn(\"CHANGED_ICU_UNIT\", \n","                when(col(\"FIRST_CAREUNIT\") != col(\"LAST_CAREUNIT\"), 1).otherwise(0))"]},{"cell_type":"markdown","id":"74662ab6-f263-402e-913f-dc04804eadff","metadata":{},"source":["## Extracting Time-based Features"]},{"cell_type":"code","execution_count":7,"id":"ef431386-85f1-4867-9aa1-f5bb84d7c8ae","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 4: Creating time-based features...\n"]}],"source":["print(\"üìä Step 4: Creating time-based features...\")\n","base_icu_df = base_icu_df \\\n","    .withColumn(\"ADMISSION_TO_ICU_HOURS\", \n","                (unix_timestamp(\"ICU_INTIME\") - unix_timestamp(\"ADMITTIME\")) / 3600) \\\n","    .withColumn(\"ICU_LOS_HOURS\", col(\"ICU_LOS_DAYS\") * 24) \\\n","    .withColumn(\"WEEKEND_ADMISSION\", \n","                when(dayofweek(\"ICU_INTIME\").isin([1, 7]), 1).otherwise(0)) \\\n","    .withColumn(\"NIGHT_ADMISSION\", \n","                when(hour(\"ICU_INTIME\").between(20, 7), 1).otherwise(0)) \\\n","    .filter(col(\"ICU_INTIME\") < col(\"ICU_OUTTIME\")) \\\n","    .filter(col(\"ADMITTIME\") <= col(\"ICU_INTIME\")) \\\n","    .filter(col(\"ICU_LOS_DAYS\") > 0.04)"]},{"cell_type":"markdown","id":"779ac96b-6e5f-4fdd-84a2-043a0beaa06b","metadata":{},"source":["## Remove Outliers (Excessive Length Of Stay)"]},{"cell_type":"code","execution_count":8,"id":"b6ce0e40-182e-4fbd-bb35-2bb23ed0d0de","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 5: Cleaning target variable...\n"]},{"name":"stderr","output_type":"stream","text":["25/06/01 11:06:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"]},{"data":{"text/plain":["DataFrame[ICUSTAY_ID: int, SUBJECT_ID: int, HADM_ID: int, ICU_LOS_DAYS: double, FIRST_CAREUNIT: string, LAST_CAREUNIT: string, ICU_INTIME: timestamp, ICU_OUTTIME: timestamp, GENDER: string, DOB: timestamp, PATIENT_DIED: int, ADMITTIME: timestamp, DISCHTIME: timestamp, ADMISSION_TYPE: string, ADMISSION_LOCATION: string, INSURANCE: string, ETHNICITY: string, HOSPITAL_DEATH: int, ADMISSION_DIAGNOSIS: string, AGE_AT_ICU_ADMISSION: bigint, GENDER_BINARY: int, IS_EMERGENCY_ADMISSION: int, IS_ELECTIVE_ADMISSION: int, CAME_FROM_ER: int, HAS_MEDICARE: int, IS_WHITE_ETHNICITY: int, FIRST_UNIT_MICU: int, FIRST_UNIT_SICU: int, FIRST_UNIT_CSRU: int, FIRST_UNIT_CCU: int, FIRST_UNIT_TSICU: int, CHANGED_ICU_UNIT: int, ADMISSION_TO_ICU_HOURS: double, ICU_LOS_HOURS: double, WEEKEND_ADMISSION: int, NIGHT_ADMISSION: int]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["print(\"üìä Step 5: Cleaning target variable...\")\n","\n","base_icu_df = base_icu_df.filter(col(\"ICU_LOS_DAYS\").between(0.1, 15))\n","\n","base_icu_df.cache()"]},{"cell_type":"markdown","id":"d4a1aa14-d750-44e7-9b44-c0f37dc4dfaa","metadata":{},"source":["## Show Dataset Info"]},{"cell_type":"code","execution_count":9,"id":"8d6cadf4-d2ab-4242-808d-73575be75130","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Master ICU dataset created!\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["üìè Dataset size: 16 ICU stays\n","üìä Features created: 36 columns\n","\n","üìã Sample of regression features:\n","+----------+--------------------+-------------+------------+--------------+----------------------+----------------------+\n","|ICUSTAY_ID|AGE_AT_ICU_ADMISSION|GENDER_BINARY|ICU_LOS_DAYS|FIRST_CAREUNIT|IS_EMERGENCY_ADMISSION|ADMISSION_TO_ICU_HOURS|\n","+----------+--------------------+-------------+------------+--------------+----------------------+----------------------+\n","|    255819|                  56|            0|       0.758|          MICU|                     1|     4.977777777777778|\n","|    231977|                  30|            0|      0.9792|          MICU|                     1|     69.51611111111112|\n","|    264061|                  51|            1|      1.0576|          CSRU|                     1|  0.016944444444444446|\n","|    248205|                  47|            0|        4.05|          MICU|                     1|   0.04055555555555555|\n","|    279243|                  29|            1|      1.6863|          MICU|                     1|  0.015833333333333335|\n","+----------+--------------------+-------------+------------+--------------+----------------------+----------------------+\n","only showing top 5 rows\n","\n","\n","üìà ICU Length of Stay Statistics:\n","+-------+-----------------+\n","|summary|     ICU_LOS_DAYS|\n","+-------+-----------------+\n","|  count|               16|\n","|   mean|        2.2869125|\n","| stddev|2.035743709106494|\n","|    min|            0.758|\n","|    max|           8.9163|\n","+-------+-----------------+\n","\n","\n","‚è∞ Feature engineering completed at: 2025-06-01 11:06:55\n"]}],"source":["print(\"‚úÖ Master ICU dataset created!\")\n","print(f\"üìè Dataset size: {base_icu_df.count():,} ICU stays\")\n","print(f\"üìä Features created: {len(base_icu_df.columns)} columns\")\n","\n","# Display sample of the dataset\n","print(\"\\nüìã Sample of regression features:\")\n","base_icu_df.select(\n","    \"ICUSTAY_ID\", \"AGE_AT_ICU_ADMISSION\", \"GENDER_BINARY\", \"ICU_LOS_DAYS\", \n","    \"FIRST_CAREUNIT\", \"IS_EMERGENCY_ADMISSION\", \"ADMISSION_TO_ICU_HOURS\"\n",").show(5)\n","\n","# Show basic statistics of target variable\n","print(\"\\nüìà ICU Length of Stay Statistics:\")\n","base_icu_df.select(\"ICU_LOS_DAYS\").describe().show()\n","\n","print(f\"\\n‚è∞ Feature engineering completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"]},{"cell_type":"markdown","id":"268129f5-72e2-40a5-b676-cbd825ae84c8","metadata":{},"source":["## Extracting Clinical Features"]},{"cell_type":"code","execution_count":10,"id":"9dc92782-4f16-4c82-bd8a-44ed78e92965","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üéØ Processing 16 ICU stays for 6 vital signs\n","üìä Filtering CHARTEVENTS...\n","üìä Processing vital signs within first 24 hours...\n","‚úÖ 24-hour vital signs data ready\n","   üìä Processing HEART_RATE...\n","   üìä Processing SBP...\n","   üìä Processing DBP...\n","   üìä Processing RESP_RATE...\n","   üìä Processing TEMPERATURE...\n","   üìä Processing SPO2...\n","‚úÖ Vital signs features created for vital_features_count ICU stays\n"]}],"source":["# Key vital signs ITEMID mappings (common across MIMIC-III)\n","vital_signs_items = {\n","    220045: \"HEART_RATE\",      # Heart Rate\n","    220050: \"SBP\",             # Systolic BP  \n","    220051: \"DBP\",             # Diastolic BP\n","    220210: \"RESP_RATE\",       # Respiratory Rate\n","    223762: \"TEMPERATURE\",     # Temperature Celsius\n","    220277: \"SPO2\"             # Oxygen Saturation\n","}\n","\n","# Get ICU IDs (using existing approach)\n","icu_ids_list = [row[\"ICUSTAY_ID\"] for row in base_icu_df.select(\"ICUSTAY_ID\").collect()]\n","print(f\"üéØ Processing {len(icu_ids_list)} ICU stays for {len(vital_signs_items)} vital signs\")\n","\n","vital_items_list = list(vital_signs_items.keys())\n","\n","\n","\n","#chartevents_sample = chartevents_df.sample(0.5, seed=42)  # 50% of 33GB\n","#print(\"‚úÖ Created CHARTEVENTS sample for processing\")\n","\n","\n","\n","print(\"üìä Filtering CHARTEVENTS...\")\n","chartevents_prefiltered = chartevents_df \\\n","    .filter(col(\"ITEMID\").isin(vital_items_list)) \\\n","    .filter(col(\"VALUENUM\").isNotNull()) \\\n","    .filter(col(\"VALUENUM\").between(1, 500)) \\\n","    .filter(col(\"ICUSTAY_ID\").isin(icu_ids_list)) \\\n","    .filter(col(\"CHARTTIME\").isNotNull()) \\\n","    .join(base_icu_df.select(\"ICUSTAY_ID\", \"ICU_INTIME\", \"ICU_OUTTIME\"), \"ICUSTAY_ID\", \"inner\") \\\n","    .filter(col(\"CHARTTIME\").between(col(\"ICU_INTIME\"), col(\"ICU_OUTTIME\"))) \\\n","    .select(\"ICUSTAY_ID\", \"ITEMID\", \"CHARTTIME\", \"VALUENUM\") \\\n","    .repartition(50, \"ICUSTAY_ID\")\n","\n","# This should complete quickly now!\n","#filtered_count = chartevents_prefiltered.count()\n","#print(f\"‚úÖ Filtered CHARTEVENTS sample: {filtered_count:,} rows\")\n","\n","# Continue with your processing pipeline\n","print(\"üìä Processing vital signs within first 24 hours...\")\n","\n","vitals_24h = chartevents_prefiltered.alias(\"ce\") \\\n","    .join(base_icu_df.select(\"ICUSTAY_ID\", \"ICU_INTIME\"), \"ICUSTAY_ID\", \"inner\") \\\n","    .filter(\n","        col(\"ce.CHARTTIME\").between(\n","            col(\"ICU_INTIME\"), \n","            col(\"ICU_INTIME\") + expr(\"INTERVAL 24 HOURS\")\n","        )\n","    )\n","\n","print(\"‚úÖ 24-hour vital signs data ready\")\n","\n","\n","\n","vital_signs_items = {\n","    220045: \"HEART_RATE\",\n","    220050: \"SBP\", \n","    220051: \"DBP\",\n","    220210: \"RESP_RATE\",\n","    223762: \"TEMPERATURE\",\n","    220277: \"SPO2\"\n","}\n","\n","# Start with base ICU dataframe\n","vitals_features = base_icu_df.select(\"ICUSTAY_ID\")\n","\n","# Add each vital sign as separate joins (faster than pivot)\n","for itemid, name in vital_signs_items.items():\n","    print(f\"   üìä Processing {name}...\")\n","    \n","    vital_stats = vitals_24h \\\n","        .filter(col(\"ITEMID\") == itemid) \\\n","        .groupBy(\"ICUSTAY_ID\") \\\n","        .agg(\n","            avg(\"VALUENUM\").alias(f\"{name}_AVG\"),\n","            min(\"VALUENUM\").alias(f\"{name}_MIN\"),\n","            max(\"VALUENUM\").alias(f\"{name}_MAX\"),\n","            stddev(\"VALUENUM\").alias(f\"{name}_STD\"),\n","            count(\"VALUENUM\").alias(f\"{name}_COUNT\")\n","        )\n","    \n","    # Left join to maintain all ICU stays\n","    vitals_features = vitals_features.join(vital_stats, \"ICUSTAY_ID\", \"left\")\n","\n","    \n","chartevents_df.unpersist()\n","vitals_24h.unpersist()\n","\n","#print(\"üìä Counting final features...\")\n","#feature_count = vitals_features.count()\n","print(f\"‚úÖ Vital signs features created for vital_features_count ICU stays\")\n","\n","# Show sample of features\n","#print(\"üìä Sample features:\")\n","#vitals_features.show(5)\n","\n"]},{"cell_type":"code","execution_count":11,"id":"5b685f0e-f499-4adf-9fd9-a6f92e22a1cf","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üß™ Step 2: Creating laboratory features from LABEVENTS...\n","   üìä Calculating laboratory statistics (first 24h)...\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 31:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["   ‚úÖ Laboratory features created for 16 ICU stays\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["print(\"\\nüß™ Step 2: Creating laboratory features from LABEVENTS...\")\n","\n","# Key lab test ITEMID mappings\n","lab_items = {\n","    50912: \"CREATININE\",       # Creatinine\n","    50902: \"CHLORIDE\",         # Chloride\n","    50931: \"GLUCOSE\",          # Glucose\n","    50983: \"SODIUM\",           # Sodium\n","    50971: \"POTASSIUM\",        # Potassium\n","    51222: \"HEMOGLOBIN\",       # Hemoglobin\n","    51265: \"PLATELET\",         # Platelet Count\n","    51301: \"WBC\",              # White Blood Cells\n","    50820: \"PH\"                # pH\n","}\n","\n","# Filter lab events within first 24 hours of ICU stay\n","labs_24h = labevents_df.alias(\"le\") \\\n","    .join(base_icu_df.select(\"ICUSTAY_ID\", \"HADM_ID\", \"ICU_INTIME\"), \"HADM_ID\", \"inner\") \\\n","    .filter(col(\"le.ITEMID\").isin(list(lab_items.keys()))) \\\n","    .filter(col(\"le.VALUENUM\").isNotNull()) \\\n","    .filter(col(\"le.VALUENUM\") > 0) \\\n","    .filter(\n","        col(\"le.CHARTTIME\").between(\n","            col(\"ICU_INTIME\") - expr(\"INTERVAL 6 HOURS\"),  # Include pre-ICU labs\n","            col(\"ICU_INTIME\") + expr(\"INTERVAL 24 HOURS\")\n","        )\n","    )\n","\n","# Calculate lab value statistics\n","print(\"   üìä Calculating laboratory statistics (first 24h)...\")\n","\n","labs_stats = labs_24h.groupBy(\"ICUSTAY_ID\", \"ITEMID\") \\\n","    .agg(\n","        avg(\"VALUENUM\").alias(\"avg_value\"),\n","        min(\"VALUENUM\").alias(\"min_value\"),\n","        max(\"VALUENUM\").alias(\"max_value\"),\n","        first(\"VALUENUM\").alias(\"first_value\")  # First available value\n","    )\n","\n","\n","\n","# Pivot lab results\n","labs_features = labs_stats.groupBy(\"ICUSTAY_ID\").pivot(\"ITEMID\").agg(\n","    first(\"avg_value\").alias(\"avg\"),\n","    first(\"first_value\").alias(\"first\")\n",")\n","\n","\n","# Rename lab columns\n","for itemid, name in lab_items.items():\n","    labs_features = labs_features \\\n","        .withColumnRenamed(f\"{itemid}_avg\", f\"{name}_AVG\") \\\n","        .withColumnRenamed(f\"{itemid}_first\", f\"{name}_FIRST\")\n","\n","print(f\"   ‚úÖ Laboratory features created for {labs_features.count():,} ICU stays\")"]},{"cell_type":"code","execution_count":12,"id":"94a414c1-7139-4e27-a5e4-767919a3eead","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üè• Step 3: Creating diagnosis features from ICD codes...\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 37:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["   ‚úÖ Diagnosis features created for 40 admissions\n","\n","‚è∞ Clinical features completed at: 2025-06-01 11:07:05\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["print(\"\\nüè• Step 3: Creating diagnosis features from ICD codes...\")\n","\n","# Count number of diagnoses per admission (comorbidity burden)\n","diagnosis_counts = diagnoses_df.groupBy(\"HADM_ID\") \\\n","    .agg(\n","        count(\"ICD9_CODE\").alias(\"TOTAL_DIAGNOSES\"),\n","        collect_list(\"ICD9_CODE\").alias(\"DIAGNOSIS_CODES\")\n","    )\n","\n","# Create features for common diagnosis categories\n","diagnosis_features = diagnosis_counts \\\n","    .withColumn(\"HAS_SEPSIS\", \n","                when(array_contains(col(\"DIAGNOSIS_CODES\"), \"99591\") | \n","                     array_contains(col(\"DIAGNOSIS_CODES\"), \"99592\"), 1).otherwise(0)) \\\n","    .withColumn(\"HAS_RESPIRATORY_FAILURE\",\n","                when(array_contains(col(\"DIAGNOSIS_CODES\"), \"51881\") |\n","                     array_contains(col(\"DIAGNOSIS_CODES\"), \"51882\"), 1).otherwise(0)) \\\n","    .withColumn(\"HAS_CARDIAC_ARREST\",\n","                when(array_contains(col(\"DIAGNOSIS_CODES\"), \"4275\"), 1).otherwise(0)) \\\n","    .drop(\"DIAGNOSIS_CODES\")\n","\n","\n","\n","#diagnosis_counts.unpersist()\n","\n","\n","print(f\"   ‚úÖ Diagnosis features created for {diagnosis_features.count():,} admissions\")\n","\n","print(f\"\\n‚è∞ Clinical features completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"]},{"cell_type":"markdown","id":"b27d9140-230d-4bc0-91ae-fd9db043e5a5","metadata":{},"source":["# Joining All Features"]},{"cell_type":"code","execution_count":13,"id":"1fe76c11-fb64-4b12-9a37-8efccf76d55d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 1: Joining base features with clinical data...\n","   ü´Ä Adding vital signs features...\n","   üß™ Adding laboratory features...\n","   üè• Adding diagnosis features...\n","‚úÖ All features joined! Final Dataset\n","‚úÖ Cleared from memory and disk\n","\n","üîß Step 2: Handling missing values...\n","‚úÖ Missing values handled\n","üîß Fixing data types for ML...\n","‚úÖ Data types fixed!\n"]}],"source":["print(\"üìä Step 1: Joining base features with clinical data...\")\n","\n","# Start with base ICU dataset\n","final_dataset = base_icu_df\n","\n","\n","\n","print(\"   ü´Ä Adding vital signs features...\")\n","final_dataset = final_dataset.join(vitals_features, \"ICUSTAY_ID\", \"left\")\n","\n","print(\"   üß™ Adding laboratory features...\")\n","final_dataset = final_dataset.join(labs_features, \"ICUSTAY_ID\", \"left\")\n","\n","print(\"   üè• Adding diagnosis features...\")\n","final_dataset = final_dataset.join(diagnosis_features, \"HADM_ID\", \"left\")\n","\n","print(f\"‚úÖ All features joined! Final Dataset\")\n","\n","base_icu_df.unpersist()\n","vitals_features.unpersist()\n","labs_features.unpersist()\n","diagnosis_features.unpersist()\n","\n","\n","print(f\"‚úÖ Cleared from memory and disk\")\n","\n","# ============================================================================\n","# HANDLE MISSING VALUES\n","# ============================================================================\n","\n","print(\"\\nüîß Step 2: Handling missing values...\")\n","\n","# Fill missing diagnosis counts with 0\n","final_dataset = final_dataset.fillna({\n","    \"TOTAL_DIAGNOSES\": 0,\n","    \"HAS_SEPSIS\": 0, \n","    \"HAS_RESPIRATORY_FAILURE\": 0,\n","    \"HAS_CARDIAC_ARREST\": 0\n","})\n","\n","# Fill missing vital signs with population medians (approximate values)\n","vital_defaults = {\n","    \"HEART_RATE_AVG\": 80, \"HEART_RATE_MIN\": 65, \"HEART_RATE_MAX\": 100, \"HEART_RATE_STD\": 15,\n","    \"SBP_AVG\": 120, \"SBP_MIN\": 100, \"SBP_MAX\": 140, \"SBP_STD\": 20,\n","    \"DBP_AVG\": 70, \"DBP_MIN\": 55, \"DBP_MAX\": 85, \"DBP_STD\": 15,\n","    \"RESP_RATE_AVG\": 18, \"RESP_RATE_MIN\": 12, \"RESP_RATE_MAX\": 24, \"RESP_RATE_STD\": 6,\n","    \"TEMPERATURE_AVG\": 37.0, \"TEMPERATURE_MIN\": 36.5, \"TEMPERATURE_MAX\": 37.5, \"TEMPERATURE_STD\": 0.5,\n","    \"SPO2_AVG\": 97, \"SPO2_MIN\": 95, \"SPO2_MAX\": 99, \"SPO2_STD\": 2\n","}\n","\n","final_dataset = final_dataset.fillna(vital_defaults)\n","\n","# Fill missing lab values with population medians\n","lab_defaults = {\n","    \"CREATININE_AVG\": 1.0, \"CREATININE_FIRST\": 1.0,\n","    \"CHLORIDE_AVG\": 102, \"CHLORIDE_FIRST\": 102,\n","    \"GLUCOSE_AVG\": 120, \"GLUCOSE_FIRST\": 120,\n","    \"SODIUM_AVG\": 140, \"SODIUM_FIRST\": 140,\n","    \"POTASSIUM_AVG\": 4.0, \"POTASSIUM_FIRST\": 4.0,\n","    \"HEMOGLOBIN_AVG\": 11.0, \"HEMOGLOBIN_FIRST\": 11.0,\n","    \"PLATELET_AVG\": 250, \"PLATELET_FIRST\": 250,\n","    \"WBC_AVG\": 8.5, \"WBC_FIRST\": 8.5,\n","    \"PH_AVG\": 7.4, \"PH_FIRST\": 7.4\n","}\n","\n","final_dataset = final_dataset.fillna(lab_defaults)\n","\n","# Fill remaining missing values with 0\n","final_dataset = final_dataset.fillna(0)\n","\n","\n","print(\"‚úÖ Missing values handled\")\n","\n","print(\"üîß Fixing data types for ML...\")\n","\n","# Cast problematic string columns to double\n","from pyspark.sql.functions import col\n","\n","string_columns = [\n","    \"CREATININE_FIRST\", \"GLUCOSE_FIRST\", \"SODIUM_FIRST\", \"POTASSIUM_FIRST\",\n","    \"HEMOGLOBIN_FIRST\", \"PLATELET_FIRST\", \"WBC_FIRST\", \"PH_FIRST\"\n","]\n","\n","for col_name in string_columns:\n","    if col_name in final_dataset.columns:\n","        final_dataset = final_dataset.withColumn(\n","            col_name, \n","            col(col_name).cast(\"double\")\n","        )\n","\n","# Fill any nulls created during conversion\n","final_dataset = final_dataset.fillna({\n","    \"CREATININE_FIRST\": 1.0,\n","    \"GLUCOSE_FIRST\": 120.0,\n","    \"SODIUM_FIRST\": 140.0,\n","    \"POTASSIUM_FIRST\": 4.0,\n","    \"HEMOGLOBIN_FIRST\": 11.0,\n","    \"PLATELET_FIRST\": 250.0,\n","    \"WBC_FIRST\": 8.5,\n","    \"PH_FIRST\": 7.4\n","})\n","\n","print(\"‚úÖ Data types fixed!\")\n"]},{"cell_type":"code","execution_count":14,"id":"88f6f328-17d8-40a6-ba45-769f22203346","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìã Step 3: Selecting final features for regression modeling...\n","‚úÖ Final modeling dataset prepared!\n","üìä Total features: 39 predictive features\n","üéØ Target variable: ICU_LOS_DAYS (continuous)\n","\n","üìã Feature categories:\n","   üë§ Demographics: 2 features\n","   üè• Admission: 8 features\n","   üè¢ ICU Unit: 6 features\n","   ü´Ä Vital Signs: 11 features\n","   üß™ Laboratory: 8 features\n","   ü©∫ Diagnoses: 4 features\n","\n","‚è∞ Dataset preparation completed at: 2025-06-01 11:07:07\n","üöÄ Ready for train/test split and model training!\n"]}],"source":["print(\"\\nüìã Step 3: Selecting final features for regression modeling...\")\n","\n","# Define feature columns for modeling\n","feature_columns = [\n","    # Demographics\n","    \"AGE_AT_ICU_ADMISSION\", \"GENDER_BINARY\",\n","    \n","    # Admission characteristics\n","    \"IS_EMERGENCY_ADMISSION\", \"IS_ELECTIVE_ADMISSION\", \"CAME_FROM_ER\",\n","    \"HAS_MEDICARE\", \"IS_WHITE_ETHNICITY\", \"ADMISSION_TO_ICU_HOURS\",\n","    \"WEEKEND_ADMISSION\", \"NIGHT_ADMISSION\",\n","    \n","    # ICU unit features\n","    \"FIRST_UNIT_MICU\", \"FIRST_UNIT_SICU\", \"FIRST_UNIT_CSRU\", \n","    \"FIRST_UNIT_CCU\", \"FIRST_UNIT_TSICU\", \"CHANGED_ICU_UNIT\",\n","    \n","    # Vital signs (averages)\n","    \"HEART_RATE_AVG\", \"SBP_AVG\", \"DBP_AVG\", \"RESP_RATE_AVG\", \n","    \"TEMPERATURE_AVG\", \"SPO2_AVG\",\n","    \n","    # Vital signs (variability)\n","    \"HEART_RATE_STD\", \"SBP_STD\", \"DBP_STD\", \"RESP_RATE_STD\", \"SPO2_STD\",\n","    \n","    # Laboratory values\n","    \"CREATININE_FIRST\", \"GLUCOSE_FIRST\", \"SODIUM_FIRST\", \"POTASSIUM_FIRST\",\n","    \"HEMOGLOBIN_FIRST\", \"PLATELET_FIRST\", \"WBC_FIRST\", \"PH_FIRST\",\n","    \n","    # Diagnosis features\n","    \"TOTAL_DIAGNOSES\", \"HAS_SEPSIS\", \"HAS_RESPIRATORY_FAILURE\", \"HAS_CARDIAC_ARREST\"\n","]\n","\n","# Create modeling dataset with selected features\n","modeling_dataset = final_dataset.select(\n","    [\"ICUSTAY_ID\", \"ICU_LOS_DAYS\"] + feature_columns\n",")\n","\n","# Remove any remaining nulls and invalid records\n","modeling_dataset = modeling_dataset.filter(col(\"ICU_LOS_DAYS\").isNotNull()) \\\n","    .filter(col(\"ICU_LOS_DAYS\") > 0) \\\n","    .filter(col(\"AGE_AT_ICU_ADMISSION\").between(18,80))\n","\n","# Cache the final dataset\n","#modeling_dataset = modeling_dataset.repartition(200)\n","#modeling_dataset.cache()\n","\n","\n","print(f\"‚úÖ Final modeling dataset prepared!\")\n","#print(f\"üìè Final dataset: {modeling_dataset.count():,} ICU stays\")\n","print(f\"üìä Total features: {len(feature_columns)} predictive features\")\n","print(f\"üéØ Target variable: ICU_LOS_DAYS (continuous)\")\n","\n","# Show feature summary\n","print(f\"\\nüìã Feature categories:\")\n","print(f\"   üë§ Demographics: 2 features\")\n","print(f\"   üè• Admission: 8 features\") \n","print(f\"   üè¢ ICU Unit: 6 features\")\n","print(f\"   ü´Ä Vital Signs: 11 features\")\n","print(f\"   üß™ Laboratory: 8 features\")\n","print(f\"   ü©∫ Diagnoses: 4 features\")\n","\n","# Display sample of final dataset\n","#print(f\"\\nüìã Sample of final modeling dataset:\")\n","#modeling_dataset.select(\"ICUSTAY_ID\", \"ICU_LOS_DAYS\", \"AGE_AT_ICU_ADMISSION\", \n","#                       \"HEART_RATE_AVG\", \"CREATININE_FIRST\", \"HAS_SEPSIS\").show(5)\n","\n","# Basic statistics of target variable\n","#print(f\"\\nüìà Final ICU Length of Stay Statistics:\")\n","#modeling_dataset.select(\"ICU_LOS_DAYS\").describe().show()\n","\n","print(f\"\\n‚è∞ Dataset preparation completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","print(f\"üöÄ Ready for train/test split and model training!\")"]},{"cell_type":"markdown","id":"5fa7f975-668b-4ab3-a228-4af82187778e","metadata":{},"source":["## Preparing for Machine Learning"]},{"cell_type":"code","execution_count":15,"id":"50fa7d59-2d01-4dcf-868f-900431b44be9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 1: Creating train/test split...\n","‚úÖ Data split completed:\n","\n","üîß Step 2: Assembling feature vectors...\n","‚úÖ Feature vectors assembled:\n","   üìä Feature vector size: 39 dimensions\n"]},{"data":{"text/plain":["'\\nprint(\"\\n‚öñÔ∏è Step 3: Scaling features...\")\\n\\n# Create StandardScaler to normalize features\\nscaler = StandardScaler(\\n    inputCol=\"features_raw\",\\n    outputCol=\"features\",\\n    withStd=True,\\n    withMean=True\\n)\\n\\n# Fit scaler on training data\\nscaler_model = scaler.fit(train_assembled)\\ntrain_scaled = scaler_model.transform(train_assembled)\\ntest_scaled = scaler_model.transform(test_assembled)\\n\\n# Cache the final processed datasets\\ntrain_scaled.cache()\\ntest_scaled.cache()\\n\\n\\nprint(f\"‚úÖ Feature scaling completed:\")\\nprint(f\"   üìä Features standardized (mean=0, std=1)\")\\nprint(f\"   üîß Scaler fitted on training data only\")\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(\"üìä Step 1: Creating train/test split...\")\n","\n","# Split the data (80% train, 20% test)\n","train_data, test_data = modeling_dataset.randomSplit([0.8, 0.2], seed=42)\n","\n","# Cache both datasets for performance\n","train_data.cache()\n","test_data.cache()\n","\n","\n","modeling_dataset.unpersist()\n","\n","print(f\"‚úÖ Data split completed:\")\n","#print(f\"   üìà Training set: {train_data.count():,} ICU stays ({train_data.count()/modeling_dataset.count()*100:.1f}%)\")\n","#print(f\"   üìä Test set: {test_data.count():,} ICU stays ({test_data.count()/modeling_dataset.count()*100:.1f}%)\")\n","\n","# Show target variable distribution in both sets\n","#print(f\"\\nüìà Target variable distribution:\")\n","#print(f\"Training set LOS statistics:\")\n","#train_data.select(\"ICU_LOS_DAYS\").describe().show()\n","\n","#print(f\"Test set LOS statistics:\")\n","#test_data.select(\"ICU_LOS_DAYS\").describe().show()\n","\n","# ============================================================================\n","# FEATURE VECTOR ASSEMBLY\n","# ============================================================================\n","\n","print(\"\\nüîß Step 2: Assembling feature vectors...\")\n","\n","# Create feature vector assembler\n","feature_assembler = VectorAssembler(\n","    inputCols=feature_columns,\n","    outputCol=\"features_raw\"\n",")\n","\n","# Apply feature assembler to training data\n","train_assembled = feature_assembler.transform(train_data)\n","test_assembled = feature_assembler.transform(test_data)\n","\n","print(f\"‚úÖ Feature vectors assembled:\")\n","print(f\"   üìä Feature vector size: {len(feature_columns)} dimensions\")\n","\n","# ============================================================================\n","# FEATURE SCALING\n","# ============================================================================\n","'''\n","print(\"\\n‚öñÔ∏è Step 3: Scaling features...\")\n","\n","# Create StandardScaler to normalize features\n","scaler = StandardScaler(\n","    inputCol=\"features_raw\",\n","    outputCol=\"features\",\n","    withStd=True,\n","    withMean=True\n",")\n","\n","# Fit scaler on training data\n","scaler_model = scaler.fit(train_assembled)\n","train_scaled = scaler_model.transform(train_assembled)\n","test_scaled = scaler_model.transform(test_assembled)\n","\n","# Cache the final processed datasets\n","train_scaled.cache()\n","test_scaled.cache()\n","\n","\n","print(f\"‚úÖ Feature scaling completed:\")\n","print(f\"   üìä Features standardized (mean=0, std=1)\")\n","print(f\"   üîß Scaler fitted on training data only\")\n","'''"]},{"cell_type":"markdown","id":"8b1aa2af-6e65-4688-84ac-724a79f8ba00","metadata":{},"source":["## Final Dataset Preparation"]},{"cell_type":"code","execution_count":16,"id":"c2397a40-5d63-475b-a2dc-4b9f2fe4233b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìã Step 4: Preparing final ML datasets...\n","\n","üìã Caching...\n","‚úÖ Final ML datasets prepared:\n","   üéØ Target variable: 'label' (ICU_LOS_DAYS)\n","   üìä Features: 'features' (scaled vector)\n","   üîë Identifier: 'ICUSTAY_ID'\n","‚è∞ Preprocessing completed at: 2025-06-01 11:07:12\n"]}],"source":["\n","print(\"\\nüìã Step 4: Preparing final ML datasets...\")\n","\n","# Select columns needed for modeling\n","ml_columns = [\"ICUSTAY_ID\", \"ICU_LOS_DAYS\", \"features\"]\n","\n","#train_final = train_scaled.select(ml_columns).withColumnRenamed(\"ICU_LOS_DAYS\", \"label\")\n","#test_final = test_scaled.select(ml_columns).withColumnRenamed(\"ICU_LOS_DAYS\", \"label\")\n","\n","#train_final = train_assembled.select(ml_columns).withColumnRenamed(\"ICU_LOS_DAYS\", \"label\")\n","#test_final = test_assembled.select(ml_columns).withColumnRenamed(\"ICU_LOS_DAYS\", \"label\")\n","\n","\n","train_final = train_assembled.select(\"ICUSTAY_ID\", \"ICU_LOS_DAYS\", \"features_raw\") \\\n","    .withColumnRenamed(\"ICU_LOS_DAYS\", \"label\") \\\n","    .withColumnRenamed(\"features_raw\", \"features\")\n","\n","test_final = test_assembled.select(\"ICUSTAY_ID\", \"ICU_LOS_DAYS\", \"features_raw\") \\\n","    .withColumnRenamed(\"ICU_LOS_DAYS\", \"label\") \\\n","    .withColumnRenamed(\"features_raw\", \"features\")\n","\n","\n","\n","\n","print(\"\\nüìã Caching...\")\n","\n","# Cache final datasets\n","train_final.cache()\n","test_final.cache()\n","\n","print(f\"‚úÖ Final ML datasets prepared:\")\n","print(f\"   üéØ Target variable: 'label' (ICU_LOS_DAYS)\")\n","print(f\"   üìä Features: 'features' (scaled vector)\")\n","print(f\"   üîë Identifier: 'ICUSTAY_ID'\")\n","\n","# Show sample of final datasets\n","#print(f\"\\nüìã Sample of training data structure:\")\n","#train_final.select(\"ICUSTAY_ID\", \"label\").show(5)\n","\n","#print(f\"\\nüìã Feature vector example (first 10 features):\")\n","# Show first few elements of feature vector for one sample\n","#sample_features = train_final.select(\"features\").take(1)[0][\"features\"]\n","#print(f\"   üìä Feature vector sample: {sample_features.toArray()[:10]}...\")\n","#print(f\"   üìè Total feature dimensions: {len(sample_features.toArray())}\")\n","\n","# ============================================================================\n","# DATA QUALITY CHECKS\n","# ============================================================================\n","'''\n","print(f\"\\nüîç Step 5: Final data quality checks...\")\n","\n","# Check for any remaining nulls\n","train_nulls = train_final.filter(col(\"label\").isNull() | col(\"features\").isNull()).count()\n","test_nulls = test_final.filter(col(\"label\").isNull() | col(\"features\").isNull()).count()\n","\n","print(f\"   üîç Null values in training set: {train_nulls}\")\n","print(f\"   üîç Null values in test set: {test_nulls}\")\n","\n","# Show target variable ranges\n","train_stats = train_final.agg(\n","    min(\"label\").alias(\"min_los\"),\n","    max(\"label\").alias(\"max_los\"), \n","    avg(\"label\").alias(\"mean_los\"),\n","    stddev(\"label\").alias(\"std_los\")\n",").collect()[0]\n","\n","print(f\"\\nüìä Final training set target statistics:\")\n","print(f\"   üìâ Min LOS: {train_stats['min_los']:.2f} days\")\n","print(f\"   üìà Max LOS: {train_stats['max_los']:.2f} days\") \n","print(f\"   üìä Mean LOS: {train_stats['mean_los']:.2f} days\")\n","print(f\"   üìè Std LOS: {train_stats['std_los']:.2f} days\")\n","\n","print(f\"\\n‚úÖ Data preprocessing completed successfully!\")\n","print(f\"üöÄ Ready for model training with {len(feature_columns)} features\")\n","'''\n","\n","print(f\"‚è∞ Preprocessing completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"]},{"cell_type":"markdown","id":"f0c98beb-ae1b-445a-aa7f-9002b4d9a012","metadata":{},"source":["## Training Multiple Models"]},{"cell_type":"code","execution_count":17,"id":"eda7d1c4-c1ef-4261-a3b5-e05db415626d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Step 1: Setting up evaluation metrics...\n","‚úÖ Evaluation metrics configured: RMSE, MAE, R¬≤\n"]}],"source":["print(\"üìä Step 1: Setting up evaluation metrics...\")\n","\n","# Create regression evaluators\n","rmse_evaluator = RegressionEvaluator(\n","    labelCol=\"label\", \n","    predictionCol=\"prediction\", \n","    metricName=\"rmse\"\n",")\n","\n","mae_evaluator = RegressionEvaluator(\n","    labelCol=\"label\",\n","    predictionCol=\"prediction\", \n","    metricName=\"mae\"\n",")\n","\n","r2_evaluator = RegressionEvaluator(\n","    labelCol=\"label\",\n","    predictionCol=\"prediction\",\n","    metricName=\"r2\"\n",")\n","\n","print(\"‚úÖ Evaluation metrics configured: RMSE, MAE, R¬≤\")"]},{"cell_type":"markdown","id":"b0f74323-98d0-44fd-b21f-f2e543449457","metadata":{},"source":["### Linear Regression"]},{"cell_type":"code","execution_count":18,"id":"4a25b20c-1f60-4782-b27c-6fda0121af85","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìà Step 2: Training Linear Regression model...\n","üïê Started at: 11:07:13\n","   üîÑ Training Linear Regression...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["   üîÑ Linear Regression - Making predictions (test data)...\n","   üîÑ Linear Regression - Evaluation...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["‚úÖ Linear Regression Results:\n","   üìâ RMSE: 2.841 days\n","   üìä MAE: 2.778 days\n","   üìà R¬≤: -272.669\n","üïê Completed at: 11:07:42\n","‚è±Ô∏è Total elapsed time: 29.94 seconds\n","\n","üìà Linear Regression Predictions (Sample 20):\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 226:===========================>                        (215 + 27) / 400]\r","\r","[Stage 226:=========================================>          (323 + 24) / 400]\r"]},{"name":"stdout","output_type":"stream","text":["+----------+----------+-------------+--------------+-------------+\n","|ICUSTAY_ID|Actual_LOS|Predicted_LOS|Absolute_Error|Percent_Error|\n","+----------+----------+-------------+--------------+-------------+\n","|231977    |0.9792    |4.254        |3.275         |334.45       |\n","|252713    |0.848     |3.966        |3.118         |367.67       |\n","|298190    |1.2597    |3.2          |1.94          |154.01       |\n","+----------+----------+-------------+--------------+-------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 226:====================================================>(395 + 4) / 400]\r","\r","                                                                                \r"]}],"source":["print(\"\\nüìà Step 2: Training Linear Regression model...\")\n","print(f\"üïê Started at: {datetime.now().strftime('%H:%M:%S')}\")\n","start_time = time.time()\n","\n","# Create Linear Regression model\n","lr = LinearRegression(\n","   featuresCol=\"features\",\n","   labelCol=\"label\",\n","   maxIter=100,\n","   regParam=0.01,\n","   elasticNetParam=0.0,\n","   tol=1e-6,\n","   standardization=True,\n","   fitIntercept=True\n",")\n","\n","\n","# Train the model\n","print(\"   üîÑ Training Linear Regression...\")\n","lr_model = lr.fit(train_final)\n","\n","print(\"   üîÑ Linear Regression - Making predictions (test data)...\")\n","lr_predictions = lr_model.transform(test_final)\n","\n","print(\"   üîÑ Linear Regression - Evaluation...\")\n","lr_rmse = rmse_evaluator.evaluate(lr_predictions)\n","lr_mae = mae_evaluator.evaluate(lr_predictions)\n","lr_r2 = r2_evaluator.evaluate(lr_predictions)\n","\n","print(f\"‚úÖ Linear Regression Results:\")\n","print(f\"   üìâ RMSE: {lr_rmse:.3f} days\")\n","print(f\"   üìä MAE: {lr_mae:.3f} days\")\n","print(f\"   üìà R¬≤: {lr_r2:.3f}\")\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(f\"üïê Completed at: {datetime.now().strftime('%H:%M:%S')}\")\n","print(f\"‚è±Ô∏è Total elapsed time: {elapsed_time:.2f} seconds\")\n","\n","\n","# Linear Regression Predictions\n","\n","print(\"\\nüìà Linear Regression Predictions (Sample 20):\")\n","lr_display = lr_predictions.select(\n","    \"ICUSTAY_ID\",\n","    col(\"label\").alias(\"Actual_LOS\"),\n","    round(col(\"prediction\"), 3).alias(\"Predicted_LOS\"),\n","    round(abs(col(\"label\") - col(\"prediction\")), 3).alias(\"Absolute_Error\"),\n","    round(((abs(col(\"label\") - col(\"prediction\")) / col(\"label\")) * 100), 2).alias(\"Percent_Error\")\n",").orderBy(\"ICUSTAY_ID\")\n","\n","lr_display.show(20, truncate=False)"]},{"cell_type":"markdown","id":"6847f98b-4da8-41ff-b26f-f2943c8baa38","metadata":{},"source":["### Random Forest"]},{"cell_type":"code","execution_count":19,"id":"52707ea4-eb6a-449d-8160-7013057b2c3f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üå≤ Step 3: Training Random Forest model...\n","üïê Started at: 11:07:45\n","   üîÑ Training Random Forest...\n"]},{"name":"stderr","output_type":"stream","text":["25/06/01 11:07:46 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 13 (= number of training instances)\n","WARNING: An illegal reflective access operation has occurred                    \n","WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.5.3.jar) to field java.nio.charset.Charset.name\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n"]},{"name":"stdout","output_type":"stream","text":["   üîÑ Random Forest - Making predictions (test data)...\n","   üîÑ Random Forest - Evaluation...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["‚úÖ Random Forest Results:\n","   üìâ RMSE: 1.597 days\n","   üìä MAE: 1.588 days\n","   üìà R¬≤: -85.532\n","üïê Completed at: 11:08:06\n","‚è±Ô∏è Total elapsed time: 21.26 seconds\n","\n","üå≤ Random Forest Predictions (Sample 20):\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 266:==========================================>         (327 + 28) / 400]\r","\r","[Stage 266:==================================================>  (384 + 5) / 400]\r"]},{"name":"stdout","output_type":"stream","text":["+----------+----------+-------------+--------------+-------------+\n","|ICUSTAY_ID|Actual_LOS|Predicted_LOS|Absolute_Error|Percent_Error|\n","+----------+----------+-------------+--------------+-------------+\n","|231977    |0.9792    |2.507        |1.527         |155.98       |\n","|252713    |0.848     |2.675        |1.827         |215.5        |\n","|298190    |1.2597    |2.668        |1.408         |111.78       |\n","+----------+----------+-------------+--------------+-------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["\n","print(\"\\nüå≤ Step 3: Training Random Forest model...\")\n","print(f\"üïê Started at: {datetime.now().strftime('%H:%M:%S')}\")\n","start_time = time.time()\n","\n","# Create Random Forest model\n","rf = RandomForestRegressor(\n","    featuresCol=\"features\",\n","    labelCol=\"label\",\n","    numTrees=100,                   # Standard ensemble size\n","    maxDepth=8,                     # Good depth for complex patterns\n","    minInstancesPerNode=5,          # Allow granular splits\n","    subsamplingRate=0.8,            # 80% data sampling\n","    featureSubsetStrategy=\"sqrt\",   # sqrt(num_features) per split\n","    maxBins=32,                     # Standard binning\n","    impurity=\"variance\",            # For regression\n","    maxMemoryInMB=256,              # Standard memory allocation\n","    cacheNodeIds=True,              # Cache for performance\n","    checkpointInterval=10,          # Checkpoint every 10 iterations\n","    seed=42\n",")\n","\n","print(\"   üîÑ Training Random Forest...\")\n","rf_model = rf.fit(train_final)\n","\n","print(\"   üîÑ Random Forest - Making predictions (test data)...\")\n","rf_predictions = rf_model.transform(test_final)\n","\n","print(\"   üîÑ Random Forest - Evaluation...\")\n","rf_rmse = rmse_evaluator.evaluate(rf_predictions)\n","rf_mae = mae_evaluator.evaluate(rf_predictions)\n","rf_r2 = r2_evaluator.evaluate(rf_predictions)\n","\n","print(f\"‚úÖ Random Forest Results:\")\n","print(f\"   üìâ RMSE: {rf_rmse:.3f} days\")\n","print(f\"   üìä MAE: {rf_mae:.3f} days\")\n","print(f\"   üìà R¬≤: {rf_r2:.3f}\")\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(f\"üïê Completed at: {datetime.now().strftime('%H:%M:%S')}\")\n","print(f\"‚è±Ô∏è Total elapsed time: {elapsed_time:.2f} seconds\")\n","\n","\n","# Random Forest Predictions\n","print(\"\\nüå≤ Random Forest Predictions (Sample 20):\")\n","rf_display = rf_predictions.select(\n","    \"ICUSTAY_ID\",\n","    col(\"label\").alias(\"Actual_LOS\"),\n","    round(col(\"prediction\"), 3).alias(\"Predicted_LOS\"),\n","    round(abs(col(\"label\") - col(\"prediction\")), 3).alias(\"Absolute_Error\"),\n","    round(((abs(col(\"label\") - col(\"prediction\")) / col(\"label\")) * 100), 2).alias(\"Percent_Error\")\n",").orderBy(\"ICUSTAY_ID\")\n","\n","rf_display.show(20, truncate=False)\n"]},{"cell_type":"markdown","id":"5cc0d610-37c0-4c99-9fc0-289846b54033","metadata":{},"source":["## Model Comparison"]},{"cell_type":"code","execution_count":20,"id":"e3ff000d-87eb-4b26-976a-65db81b057f0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üèÜ Step 5: Model Performance Comparison...\n","üìä Model Performance Summary:\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 269:=====================================>                 (13 + 6) / 19]\r"]},{"name":"stdout","output_type":"stream","text":["+-----------------+------------------+------------------+------------------+\n","|Model            |RMSE              |MAE               |R2                |\n","+-----------------+------------------+------------------+------------------+\n","|Linear Regression|2.8407590201167916|2.777594641355016 |-272.669119278364 |\n","|Random Forest    |1.59739046150588  |1.5876170346681093|-85.53248573702092|\n","+-----------------+------------------+------------------+------------------+\n","\n","\n","ü•á Best Models:\n","   üéØ Lowest RMSE: Random Forest (1.597 days)\n","   üìà Highest R¬≤: Random Forest (-85.532)\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["print(\"\\nüèÜ Step 5: Model Performance Comparison...\")\n","\n","# Create comparison summary\n","results_data = [\n","    (\"Linear Regression\", lr_rmse, lr_mae, lr_r2),\n","    (\"Random Forest\", rf_rmse, rf_mae, rf_r2)\n","]\n","\n","results_df = spark.createDataFrame(results_data, [\"Model\", \"RMSE\", \"MAE\", \"R2\"])\n","\n","print(\"üìä Model Performance Summary:\")\n","results_df.show(truncate=False)\n","\n","# Find best model\n","import operator\n","import builtins\n","best_rmse_model = builtins.min(results_data, key=operator.itemgetter(1))\n","best_r2_model = builtins.max(results_data, key=operator.itemgetter(3))\n","\n","print(f\"\\nü•á Best Models:\")\n","print(f\"   üéØ Lowest RMSE: {best_rmse_model[0]} ({best_rmse_model[1]:.3f} days)\")\n","print(f\"   üìà Highest R¬≤: {best_r2_model[0]} ({best_r2_model[3]:.3f})\")"]},{"cell_type":"markdown","id":"400e166a-1c18-4e22-938c-d6a5569bd296","metadata":{},"source":["## Display Predictions"]},{"cell_type":"code","execution_count":21,"id":"068fa69e-a7fb-40f2-a287-6300bf41e03d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìà Linear Regression Predictions (Sample 20):\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+----------+----------+-------------+--------------+-------------+\n","|ICUSTAY_ID|Actual_LOS|Predicted_LOS|Absolute_Error|Percent_Error|\n","+----------+----------+-------------+--------------+-------------+\n","|231977    |0.9792    |4.254        |3.275         |334.45       |\n","|252713    |0.848     |3.966        |3.118         |367.67       |\n","|298190    |1.2597    |3.2          |1.94          |154.01       |\n","+----------+----------+-------------+--------------+-------------+\n","\n","\n","üå≤ Random Forest Predictions (Sample 20):\n","+----------+----------+-------------+--------------+-------------+\n","|ICUSTAY_ID|Actual_LOS|Predicted_LOS|Absolute_Error|Percent_Error|\n","+----------+----------+-------------+--------------+-------------+\n","|231977    |0.9792    |2.507        |1.527         |155.98       |\n","|252713    |0.848     |2.675        |1.827         |215.5        |\n","|298190    |1.2597    |2.668        |1.408         |111.78       |\n","+----------+----------+-------------+--------------+-------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 275:=========================================>          (319 + 29) / 400]\r","\r","                                                                                \r"]}],"source":["\n","# Linear Regression Predictions\n","\n","print(\"\\nüìà Linear Regression Predictions (Sample 20):\")\n","lr_display = lr_predictions.select(\n","    \"ICUSTAY_ID\",\n","    col(\"label\").alias(\"Actual_LOS\"),\n","    round(col(\"prediction\"), 3).alias(\"Predicted_LOS\"),\n","    round(abs(col(\"label\") - col(\"prediction\")), 3).alias(\"Absolute_Error\"),\n","    round(((abs(col(\"label\") - col(\"prediction\")) / col(\"label\")) * 100), 2).alias(\"Percent_Error\")\n",").orderBy(\"ICUSTAY_ID\")\n","\n","lr_display.show(20, truncate=False)\n","\n","\n","\n","# Random Forest Predictions\n","print(\"\\nüå≤ Random Forest Predictions (Sample 20):\")\n","rf_display = rf_predictions.select(\n","    \"ICUSTAY_ID\",\n","    col(\"label\").alias(\"Actual_LOS\"),\n","    round(col(\"prediction\"), 3).alias(\"Predicted_LOS\"),\n","    round(abs(col(\"label\") - col(\"prediction\")), 3).alias(\"Absolute_Error\"),\n","    round(((abs(col(\"label\") - col(\"prediction\")) / col(\"label\")) * 100), 2).alias(\"Percent_Error\")\n",").orderBy(\"ICUSTAY_ID\")\n","\n","rf_display.show(20, truncate=False)"]},{"cell_type":"code","execution_count":null,"id":"905be484-c471-4032-9b55-207d934e8cdb","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"343e733a","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}