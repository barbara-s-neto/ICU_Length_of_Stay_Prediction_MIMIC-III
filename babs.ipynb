{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa415f02",
   "metadata": {},
   "source": [
    "# Tentativa #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier  # or any other algorithm\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator  # or MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d7878",
   "metadata": {},
   "source": [
    "## 0. Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1d909d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataMLProject\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5f879",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f5bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef4d30ae",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde8d6c",
   "metadata": {},
   "source": [
    "The tables were chose based on its properties regarding a persons' illness, bodily atributes or gravity of the situation. The tables were:\n",
    "* ChartEVents\n",
    "* Admissions\n",
    "* Diagnoses\n",
    "* ICUStays\n",
    "* InputEvents_MV\n",
    "* Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4aa7c",
   "metadata": {},
   "source": [
    "### a. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9195d1",
   "metadata": {},
   "source": [
    "The majoriry of the atributes are not useful to predict the duration of a ICU stay, therefore, for a initial analysis, we will choose the ones we consider relevant.\n",
    "\n",
    "First of all, we create temporary views of all tables into a SQL-like table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4224427",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents.createOrReplaceTempView(\"chartevents\")\n",
    "admissions.createOrReplaceTempView(\"admissions\")\n",
    "diagnoses.createOrReplaceTempView(\"diagnoses\")\n",
    "icustays.createOrReplaceTempView(\"icustays\")\n",
    "inputevents.createOrReplaceTempView(\"inputevents\")\n",
    "labevents.createOrReplaceTempView(\"labevents\")\n",
    "procedures.createOrReplaceTempView(\"procedures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134f8e1",
   "metadata": {},
   "source": [
    "SO QUEREMOS PESSOAS QUE TENHAM ICUSTAY_ID PQ: given a person admitted int he icu i have to predict for how long they are gonna be there, therefore in pre processing i will ignore the data from people that were never in the icu. The most efficient approach is to create temporary views that pre-filter the data before joining tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4915eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE OR REPLACE TEMPORARY VIEW icu_filtered AS SELECT * FROM icustays WHERE icustay_id IS NOT NULL\")\n",
    "spark.sql(\"CREATE OR REPLACE TEMPORARY VIEW chart_filtered AS SELECT * FROM chartevents WHERE icustay_id IS NOT NULL\")\n",
    "spark.sql(\"CREATE OR REPLACE TEMPORARY VIEW input_filtered AS SELECT * FROM inputevents WHERE icustay_id IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596afa5",
   "metadata": {},
   "source": [
    "To get procedures done to icu patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831615a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW proc_filtered AS\n",
    "SELECT \n",
    "    p.icd9_code,\n",
    "    icu.icustay_id\n",
    "FROM procedures p\n",
    "JOIN icustays icu ON p.hadm_id = icu.hadm_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4459387",
   "metadata": {},
   "source": [
    "To handle labevents time to be only during the icustay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e297e838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW lab_filtered AS\n",
    "SELECT \n",
    "    lab.subject_id,\n",
    "    lab.hadm_id,\n",
    "    lab.itemid,\n",
    "    lab.valuenum,\n",
    "    lab.valueuom,\n",
    "    icu.icustay_id \n",
    "FROM labevents lab\n",
    "JOIN admissions adm ON lab.hadm_id = adm.hadm_id\n",
    "JOIN icustays icu ON adm.hadm_id = icu.hadm_id\n",
    "WHERE \n",
    "    lab.charttime BETWEEN icu.intime AND icu.outtime\n",
    "    AND lab.hadm_id IS NOT NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bfc8b8",
   "metadata": {},
   "source": [
    "Then, we create a table, using a SQL query, with the relevant features for predicting the icu stay duration, and its own column (LOS from ICUStays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2eaab2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+------------+-----------+-----+----------+---------+-------+-------------+------------+------+----+-------------+--------------+--------------+-------+\n",
      "|icustay_id|admission_type|  admission_location|chart_itemid|chart_value|error|lab_itemid|lab_value|seq_num|diagnose_code|input_itemid|amount|rate|patientweight|procedure_code|first_careunit|    LOS|\n",
      "+----------+--------------+--------------------+------------+-----------+-----+----------+---------+-------+-------------+------------+------+----+-------------+--------------+--------------+-------+\n",
      "|    285977|        URGENT|TRANSFER FROM HOS...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          CSRU| 0.8181|\n",
      "|    279205|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|         TSICU| 6.6602|\n",
      "|    247324|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|           CCU| 4.0284|\n",
      "|    221620|     EMERGENCY|TRANSFER FROM HOS...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 2.7713|\n",
      "|    235270|       NEWBORN|PHYS REFERRAL/NOR...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          NICU| 3.3084|\n",
      "|    239661|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          SICU| 0.5826|\n",
      "|    210582|       NEWBORN|PHYS REFERRAL/NOR...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          NICU|  0.091|\n",
      "|    235149|     EMERGENCY|PHYS REFERRAL/NOR...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          CSRU| 4.1009|\n",
      "|    221404|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 3.3105|\n",
      "|    214854|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 1.5035|\n",
      "|    271990|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|           CCU| 6.4001|\n",
      "|    203392|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 1.7411|\n",
      "|    232833|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|         TSICU| 1.4444|\n",
      "|    294610|     EMERGENCY|CLINIC REFERRAL/P...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|           CCU| 3.2903|\n",
      "|    281427|      ELECTIVE|PHYS REFERRAL/NOR...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          CSRU|17.1131|\n",
      "|    233499|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 2.4009|\n",
      "|    298816|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 2.2156|\n",
      "|    249354|     EMERGENCY|EMERGENCY ROOM ADMIT|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          MICU| 0.7986|\n",
      "|    225173|     EMERGENCY|TRANSFER FROM HOS...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|           CCU| 6.0799|\n",
      "|    268049|     EMERGENCY|PHYS REFERRAL/NOR...|        NULL|       NULL| NULL|      NULL|     NULL|   NULL|         NULL|        NULL|  NULL|NULL|         NULL|          NULL|          CSRU| 3.0277|\n",
      "+----------+--------------+--------------------+------------+-----------+-----+----------+---------+-------+-------------+------------+------+----+-------------+--------------+--------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        icu.icustay_id,\n",
    "        adm.admission_type,\n",
    "        adm.admission_location,\n",
    "        chart.itemid AS chart_itemid,\n",
    "        chart.valuenum AS chart_value,\n",
    "        chart.error,\n",
    "        lab.itemid AS lab_itemid,\n",
    "        lab.valuenum AS lab_value,\n",
    "        diag.seq_num,\n",
    "        diag.icd9_code as diagnose_code,\n",
    "        input.itemid AS input_itemid,\n",
    "        input.amount,\n",
    "        input.rate,\n",
    "        input.patientweight,\n",
    "        proc.icd9_code as procedure_code,\n",
    "        icu.first_careunit,\n",
    "        icu.LOS\n",
    "    FROM icu_filtered icu\n",
    "    JOIN admissions adm ON icu.hadm_id = adm.hadm_id\n",
    "    LEFT JOIN chart_filtered chart ON icu.icustay_id = chart.icustay_id\n",
    "    LEFT JOIN lab_filtered lab ON icu.icustay_id = lab.icustay_id\n",
    "    LEFT JOIN diagnoses diag ON icu.hadm_id = diag.hadm_id\n",
    "    LEFT JOIN input_filtered input ON icu.icustay_id = input.icustay_id\n",
    "    LEFT JOIN proc_filtered proc ON proc.icustay_id=icu.icustay_id\n",
    "\"\"\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940abee4",
   "metadata": {},
   "source": [
    "merdas para justificar no relatorio:\n",
    "\n",
    "Juntei as tabelas icu e admissions por admissao ao hospital e nao por pessoa, pq pode haver mais doq uma admissao por pessoa. Fiz outter join pelo msm motivo, mas dps tenho de testar isso com os dados todos e nao so com as tabelas parciais\n",
    "\n",
    "na chartevents, juntei por icu stay, Each row associated with one ITEMID (e.g. 212) corresponds to an instantiation of the same measurement (e.g. heart rate) entao nao vale a pena por a coluna VALUEUOM is the unit of measurement, pq cada teste ja e feito numa unidade de medida, n vale a pena tar a dar mais do msm a ml. Vou por o erro pq se houve erro ent conta menos para a ml mas ig que e melhor q nada??? problema para a ml e nao para nos.\n",
    "\n",
    "aqui cada chartevent, ou seja, analie/teste/raiox etc corresponde as uma linha, mais tarde temos de resolver este problema pq o objetivo e prever o tempo de internacao POR ICUSTAY_ID, ent deviamos ter apenas uma linha por admissao//icustay\n",
    "\n",
    "na tabela dos diagnosticos SEQ_NUM provides the order in which the ICD diagnoses relate to the patient, o quao importante a doenca e no caso da pessoa, e ICD9_CODE contains the actual code corresponding to the diagnosis, ou seja a doenca id, por isso para dar join dou por paciente ou por admissao? aceito opinioes, por agr pus admissoes pq e oq pus no resto\n",
    "\n",
    "input events dei join pela icustay ja que so queremos analisar pacientes que ja tenham estado. Each row associated with one ITEMID which corresponds to an instantiation of the same measurement (e.g. norepinephrine) AMOUNT - the amount of a drug or substance administered to the patient (ignorando se esta em ml dl ou l pelo motivo referido acima)\n",
    "\n",
    "\n",
    "When predicting ICU length of stay (LOS), incorporating lab results can significantly improve your model's performance, but you're right that joining requires careful handling since LABEVENTS doesn't directly contain ICU stay IDs. juntar pelo ham id ou subject e dps escolher com base no tempo\n",
    "\n",
    "\n",
    "the id is the icustays\n",
    "\n",
    "justificar o left join:\n",
    "For your use case, keep the LEFT JOINs but understand why:\n",
    "\n",
    "    LEFT JOIN (icu → others) is correct because:\n",
    "\n",
    "        You want all ICU stays (base table)\n",
    "\n",
    "        You want to keep ICU stays even if they're missing some diagnoses/procedures\n",
    "\n",
    "    Don't use FULL OUTER JOIN because:\n",
    "\n",
    "        It would include diagnoses/procedures for non-ICU patients (if any exist)\n",
    "\n",
    "        Could create NULL ICU stay records which you don't want\n",
    "\n",
    "    Your current approach is good for:\n",
    "\n",
    "        One row per combination of ICU stay + diagnosis + procedure\n",
    "\n",
    "        Preserving all relationships\n",
    "\n",
    "Example of What You'll Get\n",
    "\n",
    "For a patient with:\n",
    "\n",
    "    1 ICU stay\n",
    "\n",
    "    4 diagnoses\n",
    "\n",
    "    5 procedures\n",
    "\n",
    "    10 lab results\n",
    "\n",
    "Your query will produce 4 × 5 × 10 = 200 rows for this patient (all combinations).\n",
    "\n",
    "\n",
    "FALTA:\n",
    "altura / bmi do paciente\n",
    "genero do paciente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c546ea",
   "metadata": {},
   "source": [
    "Attribute/column documentation for the table created:\n",
    "\n",
    " 1. Patient Identification\n",
    "- **icustay_id**: Unique ICU stay identifier (primary key for ICU stays)\n",
    "\n",
    " 2. Admission Information\n",
    "- **admission_type**: Type of admission (ELECTIVE, EMERGENCY, URGENT, etc.)\n",
    "- **admission_location**: Source of admission (TRANSFER FROM HOSPITAL, CLINIC REFERRAL, etc.)\n",
    "- **first_careunit**: Initial ICU care unit (MICU, SICU, CSRU, etc.)\n",
    "- **LOS**: Length of stay in ICU (in hours or days)\n",
    "\n",
    " 3. Clinical Measurements\n",
    "- **chart_itemid**: Identifier for charted measurement (foreign key to D_ITEMS)\n",
    "- **chart_value**: Numeric value of the clinical measurement\n",
    "- **chart_error**: Error flag for the measurement (if exists)\n",
    "- **lab_itemid**: Identifier for laboratory test (foreign key to D_ITEMS)\n",
    "- **lab_value**: Result value of the laboratory test\n",
    "\n",
    " 4. Diagnostic Information\n",
    "- **diagnose_code**: ICD-9 diagnosis code\n",
    "- **seq_num**: Priority/sequence number of the diagnosis (1=primary)\n",
    "\n",
    " 5. Treatment Information\n",
    "- **input_itemid**: Identifier for input event (medications/fluids)\n",
    "- **input_amount**: Quantity administered\n",
    "- **input_rate**: Rate of administration\n",
    "- **input_patientweight**: Patient weight at time of input (if recorded)\n",
    "\n",
    " 6. Procedural Information\n",
    "- **procedure_code**: ICD-9 procedure code performed during stay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52cb96",
   "metadata": {},
   "source": [
    "transform your multiple rows per ICU stay into a single row format suitable for ML modeling while preserving both continuous values and procedure/diagnosis information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237cf026",
   "metadata": {},
   "source": [
    "### a partir daqui preciso de dados bons para nao estar a fazer ghostcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef458b5",
   "metadata": {},
   "source": [
    "Handle LabEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e3bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/16 19:06:03 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+\n",
      "|icustay_id|lab_itemid|lab_value|\n",
      "+----------+----------+---------+\n",
      "+----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cache()\n",
    "\n",
    "df.createOrReplaceTempView(\"icu_data\")\n",
    "lab_features = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        icd9_code,\n",
    "        AVG(lab_value) as lab_value\n",
    "    FROM icu_data\n",
    "    WHERE lab_itemid IS NOT NULL\n",
    "    GROUP BY icustay_id, lab_itemid\n",
    "\"\"\")\n",
    "lab_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd0059",
   "metadata": {},
   "source": [
    "Handle Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f9a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|procedure_code|freq|\n",
      "+--------------+----+\n",
      "+--------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_procs = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    procedure_code,\n",
    "    COUNT(*) as freq\n",
    "FROM icu_data\n",
    "WHERE procedure_code IS NOT NULL\n",
    "GROUP BY procedure_code\n",
    "ORDER BY freq DESC\n",
    "LIMIT 100  \n",
    "\"\"\")\n",
    "\n",
    "common_procs = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    procedure_code,\n",
    "    COUNT(*) as freq\n",
    "FROM icu_data\n",
    "WHERE procedure_code IS NOT NULL\n",
    "GROUP BY procedure_code\n",
    "ORDER BY freq DESC\n",
    "LIMIT 100  \n",
    "\"\"\")\n",
    "\n",
    "common_procs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eaeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_features = df.select(\"icustay_id\").distinct()\n",
    "for proc in common_procs:\n",
    "    proc_code = proc['procedure_code']\n",
    "    has_proc = df.filter(F.col(\"procedure_code\") == proc_code) \\\n",
    "                .select(\"icustay_id\").distinct() \\\n",
    "                .withColumn(f\"proc_{proc_code}\", F.lit(1))\n",
    "    \n",
    "    proc_features = proc_features.join(\n",
    "        has_proc, \n",
    "        on=\"icustay_id\", \n",
    "        how=\"left\"\n",
    "    ).fillna(0, subset=[f\"proc_{proc_code}\"])\n",
    "\n",
    "proc_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0a499",
   "metadata": {},
   "source": [
    "### b. Handle categorical columns (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d81a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StringType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mschema[col]\u001b[38;5;241m.\u001b[39mdataType \u001b[38;5;241m==\u001b[39m StringType() \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m target_col]\n\u001b[1;32m      2\u001b[0m indexers \u001b[38;5;241m=\u001b[39m [StringIndexer(inputCol\u001b[38;5;241m=\u001b[39mcol, outputCol\u001b[38;5;241m=\u001b[39mcol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_index\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols]\n",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mschema[col]\u001b[38;5;241m.\u001b[39mdataType \u001b[38;5;241m==\u001b[39m \u001b[43mStringType\u001b[49m() \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m target_col]\n\u001b[1;32m      2\u001b[0m indexers \u001b[38;5;241m=\u001b[39m [StringIndexer(inputCol\u001b[38;5;241m=\u001b[39mcol, outputCol\u001b[38;5;241m=\u001b[39mcol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_index\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StringType' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_cols = [col for col in df.columns if df.schema[col].dataType == StringType() and col != target_col]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe35563",
   "metadata": {},
   "source": [
    "### c. Assemble features (numeric + indexed categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [col for col in df.columns if col != target_col and col not in categorical_cols]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=numeric_cols + [col+\"_index\" for col in categorical_cols],\n",
    "    outputCol=\"features_raw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeea381",
   "metadata": {},
   "source": [
    "### d. Scale features (optional but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad30fee",
   "metadata": {},
   "source": [
    "## 3. Target variable preparation (if categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indexer = StringIndexer(inputCol=target_col, outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91a495",
   "metadata": {},
   "source": [
    "## 4. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f409dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stages = indexers + [assembler, scaler, label_indexer]\n",
    "preprocessing_pipeline = Pipeline(stages=pipeline_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05217c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocessing_pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ad849",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = processed_data.randomSplit([0.7, 0.3], seed=42)\n",
    "print(f\"Training count: {train_data.count()}\")\n",
    "print(f\"Test count: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b9b79",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=100,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2abab",
   "metadata": {},
   "source": [
    "## 7. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac762e4e",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e14538",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"Test AUC = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiclass classification\n",
    "# evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "# accuracy = evaluator.evaluate(predictions)\n",
    "# print(f\"Test Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed6fd7",
   "metadata": {},
   "source": [
    "## 9. Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592609c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
